
# Abstract #

we propose a parameter-free probing technique for analyzing pre-trained language model


# Introduction #

Probing: an interesting area of research to investigate the interpretability of these pre-trained models.
A probe is a simple neural network that uses the feature representations generated by a pre-trained model(e.g., hidden state activations, attention weights) and is trained to perform a supervised task (e.g., dependency labeling)
The performance of a probe is used to measure the quality of the generated representations with the assumption that the measured quality is mostly attributable to the pre-trained language model.

However, probe introduces a new set of additional parameters, which makes the results difficult to interpret. (whether the PLM captured the linguistic information or the probe learned the downstream task itself and encode the information in its additional parameter space)

The main idea is to introduce the **Perturbed Masking** technique into the masked language modeling objective to measure the impact a word x_j has on predicting another word x_i and then induce the global linguistic properties from this inter-word information


# Perturbed Masking #

## BERT ##

1. MLM:
2. Next Sentence Prediction: given a pair of sentences, predict whether the second sentence follows the first in an original document or is taken from another random document.

## Token Perturbation ##

Given a sentence as a list of tokens \textbf{x}=[x_1, \cdots, x_T], BERT maps each x_i into a contextualized representation H_{\theta}(\textbf{x})_i, where \theta represents the network's parameters.
Our goal is to derive a function f(x_i, x_j) that captures the impact a context word x_j has on the prediction of another word x_i.

We propose a two-stage approach to achieve our goal:
1. replace x_i with the [MASK] token and feed the new sequence \textbf{x} \setminus {x_i} into BERT. We use H_\theta(\textbf{x} \setminus {x_i}) to denote the representation of x_i
2. To calculate the impact x_j \in \textbf{x} \setminus {x_i} has on H_\theta( \textbf{x} \setminus {x_i}), we further mask out x_j to obtain the second corrupted sequence \textbf{x} \setminus {x_i, x_j}. Similarly, H_\theta()\textbf{x} \setminus {x_i, x_j}) denotes the new representation of token x_i.
3. f(x_i, x_j)=d(H_\theta(\textbf{x} \setminus {x_i})_i, H_\theta(\textbf{x} \setminus {x_i, x_j})_j), where d(x, y) is the distance metric that captures the difference between two vectors.

By repeating the two-stage perburbation on each pair of token x_i, x_j \in \textbf{x} and calculating f(x_i, x_j), we obtain an impact matrix \mathcal{f} and compare them with ground-truth trees that are obtained from benchmarks.

## Span Perturbation ##

For span-level perturbation, instead of masking one token at a time, we mask an array of tokens in a span simultaneously. We obtain the span representation by averaging the representations of all the tokens the span contains.


# Visualization with Impact Maps

# Syntactic Probe

# Discourse Probe

# BERT-based Trees VS Parser-provided Trees

# Related Work

# Discussion & Conclusion



